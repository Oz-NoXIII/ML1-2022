{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab9_exercises",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, we'll experiment a bit more with the task of binary classification. We'll be considering four different classifiers, respectively the Logistic Regression, the Linear Discriminant Analysis (LDA), the Quadratic Discriminant Analysis (QDA), and Naïve Bayes. \n",
        "\n",
        "We'll be using the 'wine.csv' dataset, which contains several attributes of white wines, and each observation is associated to a binary quality value, indicating whethter the wine is of superior quality or not. The present goal is to use the above classifiers to determine the quality group of a wine based on its set of attributes. \n",
        "\n",
        "The columns of the dataframe contain the following information :\n",
        "* fixed_acidity : amount of tartaric acid in g/dm^3\n",
        "* volatile_acidity : amount of acetic acid in g/dm^3 \n",
        "* citric_acid : amount of citric acid in g/dm^3\n",
        "* residual_sugar : amount of remaining sugar after fermentation stops in g/l\n",
        "* chlorides : amount of salt in wine \n",
        "* free_sulfur_dioxide : amount of free SO2\n",
        "* total_sulfur_dioxide : amount of free and bound forms of SO2\n",
        "* density : density of the wine\n",
        "* pH : PH level of the wine on a scale from 0 to 14\n",
        "* sulphates : amount of sulphates \n",
        "* alcohol : the percent of alcohol content\n",
        "* quality : quality of the wine (1 : superior, 0 : inferior)"
      ],
      "metadata": {
        "id": "9qc8zzFDR5Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries**"
      ],
      "metadata": {
        "id": "OL2bnL0KU_Vg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtfNUtAHZEVv"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import math\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from patsy import dmatrices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration"
      ],
      "metadata": {
        "id": "yNiuBYj4XFa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Read the dataset 'wine.csv', check its properties. Check and handle possible missing values.** "
      ],
      "metadata": {
        "id": "kJLA1I0qVCwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zKQyTrqKZLmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Look at the distribution of the target variable 'quality' (using a barplot).**\n",
        "\n",
        "**Do you notice anything ?**"
      ],
      "metadata": {
        "id": "DPl9I2xuVSOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oYULnCz6ZVmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Plot a boxplot for each of the predictor variables, while separating for the quality level. Use the 'boxplot' method of the seaborn library.**\n",
        "\n",
        "**From the obtained boxplots, can you spot the 3 predictors that might seem to be most useful in predicting the target variable 'quality' ?**"
      ],
      "metadata": {
        "id": "JWrU6ky2VllI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OM_sE_Pxj64S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logisitic Regression"
      ],
      "metadata": {
        "id": "581Gr2wcW8qt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Select 'quality' as the target variable and 'density' and 'alcohol' as the predictors. Fit a logistic regression model the data, and output its summary.**\n",
        "\n",
        "**How do you interpret the obtained coefficients ? Are they significant ? What does it tell you ?** \n",
        "\n",
        "**Use the \"Logit\" model of the 'statsmodel' library, and create your input matrices using the method 'dmatrices' from the 'patsy' library. Do not split the dataset.**"
      ],
      "metadata": {
        "id": "6gqAkSWiXOm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6jZW_2WrRtsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Refit the same model as above, but introduce an interaction term between the variables 'density' and 'alcohol'.**\n",
        "\n",
        "**What do you observe ? What happened to the significance of the coefficients ?**"
      ],
      "metadata": {
        "id": "oD0tI8w-bOcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LN6B0eigOkZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Discriminant Analysis"
      ],
      "metadata": {
        "id": "n-J7MIIGgkBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Select the predictor variable 'density' and fit a LDA model to the classify the target variable 'quality'. Do not split the dataset.**\n",
        "\n",
        "**Compute the decision boundary of the model. Then, on the same plot, display the densities of the variable 'density' for each class of 'quality, and this boundary decision. What do you observe ?**\n",
        "\n",
        "**You can draw a normal distribution using the method 'norm.pdf' from the 'scipy' library. Check the attributes of the class 'LDA' to see how you can obtain the priors, the means, and the variance**"
      ],
      "metadata": {
        "id": "BSzFQjOagfDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "N9cD5dR3HyOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7) Select th variables 'sulphate' and 'alcohol' as predictor variables, and fit a LDA model to predict the variable 'quality'. Do not split the dataset.**\n",
        "\n",
        "**Draw a scatter plot of the predictor variables, while separating for the class 'quality'. Then, on the predictor space, draw the decision boundary.** \n",
        "\n",
        "**Check how you can obtain the 'coefficients' and the 'intercept' for the decision boundary [here](https://scikit-learn.org/stable/modules/lda_qda.html#lda-qda-math) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html).**"
      ],
      "metadata": {
        "id": "SesMStXDifcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6ToaKHeQa_hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiers comparison and metrics"
      ],
      "metadata": {
        "id": "DJVsvu8GkF2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8) Using the three most powerful predictors identified in exercice 3, successively fit a logistic regression model, a LDA, a QDA, and a Naïve Bayes model to predict the target variable 'quality' using a 10-folds cross-validation. Evaluate the model on its accuracy.**\n",
        "\n",
        "**For convergence issue, set the logistic regression solver to 'liblinear', and fit the intercept. The Gaussian Naïve Bayes classifier is called 'GaussianNB' is scikit-learn.**\n",
        "\n",
        "**Which of the four classifiers performs best in classifying the target variable 'quality' ?**\n"
      ],
      "metadata": {
        "id": "65ahG9PUkA8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZTPecde9HjyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9) Perform the same experiment as the previous point, but now include all predictor variables. Do you notice a significant gain in performance ?**"
      ],
      "metadata": {
        "id": "jmguu_kQldFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1wUctrK4rSdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10) Select the best model found above and the 3 most relevant predictors, split your data in train and test datasets according to a 0.8/0.2 partition, and fit it to the training data.** \n",
        "\n",
        "**Evaluate the model on the accuracy, and display the confusion matrix. You'll need to use the 'confusion_matrix' and the 'ConfusionMatrixDisplay' methods from the scikit-learn library. Can you think of any problem that might arise when evaluating the model on the accuracy ? Think of the distribution of the target variable.**"
      ],
      "metadata": {
        "id": "eHttmMLtpmBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11) Compute the True Positive Rate, the True Negative Rate, the False Positive Rate, the False Negative Rate, and the Precision. How do you interpret these metrics ? The TP, FP, TN and FN can be directly obtained from the confusion matrix.**\n",
        "\n",
        "**Draw the Receiver Operating Curve, and compute the area under the curve. You'll need the methods 'roc_curve' and 'roc_auc_score'. Does the model look to have any predictive power ?**"
      ],
      "metadata": {
        "id": "50WC2stNqs1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L3Mk0kRxZcl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qFQy0MpyrsBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}