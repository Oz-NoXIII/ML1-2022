{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab7_exercises",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**In this lab about linear regression, we'll be working with the library [StatsModel](https://www.statsmodels.org/stable/index.html), which provides numerous classes and functions for the estimation of statistical models.**\n",
        "\n",
        "**The dataset that we'll be considering is 'diamond.csv' [[1]](https://www.kaggle.com/datasets/shivam2503/diamonds), which contains several information about diverse diamonds, such as their dimensions, the quality of their cuts, their prices, etc... The goal of the lab will be to define linear regression models to best estimate diamonds prices using a bunch of predictor variables, and to understand the meaning of the obtained coefficients.**\n",
        "\n",
        "**Dataset's column information :**\n",
        "\n",
        "*   'price' : price in US dollars.\n",
        "*   'carat' : weight of the diamond. \n",
        "*   'cut' : quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
        "*   'color' : diamond's color's, from J (worst) to D (best).\n",
        "*  'clarity' : how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
        "* 'x' : length in mm.\n",
        "* 'y' : width in mm. \n",
        "* 'z' : height in mm.\n",
        "* 'table' : width of top of the diamond relative to its widest point. \n",
        "* 'depth' = 2z/(x+y) \n",
        "\n"
      ],
      "metadata": {
        "id": "5FnAdl_9MJ7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries**"
      ],
      "metadata": {
        "id": "u6jRRhX7PZQD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujsqLRDOa1-s"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from patsy import dmatrices\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Load the dataset, take a look at its properties (shape, data type, etc...). Be careful to set the dataframe incides correctly. Check for missing values, and replace them appropriately if any are present.**"
      ],
      "metadata": {
        "id": "Nd9BGtrOPfq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z0QYojPwf0-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Generate scatter plots of the variable 'price' against the variables 'x', 'y' and 'z'. Do you notice anything strange ? How would you handle such cases ?** "
      ],
      "metadata": {
        "id": "an3oV-dUZtP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AE9Eo-7_Z_0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Okib0LkJaDtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F9bG8nfEaGFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-XWKqWmJn-CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Select 'price' a the target variable and 'x' as the predictor. Fit a linear regression model to the data, and output the model's summary.**\n",
        "\n",
        "* **3.1) Is there evidence of a linear relationship between the target and the predictor variables ? What can you say regarding the statistical significance of the estimated coefficients ?**\n",
        "\n",
        "* **3.2) How do you interpret the value of the coefficients ?**\n",
        "\n",
        "* **3.3) What are the estimates' 95% confidence intervals, and how do you interpret them ?**"
      ],
      "metadata": {
        "id": "_s5Umk7Yh7YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R38E-trKm5SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Add 'y' as another predictor variable, fit the model and output its summary.**\n",
        "\n",
        "* **4.1) Is there still evidence of a linear relationship between the target and predictor variables ?**\n",
        "\n",
        "* **4.2) How do you interpret the coefficients ?**\n",
        "\n"
      ],
      "metadata": {
        "id": "839JBIPRjiAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8MLESTI2nGCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Add an interaction term between 'x' and 'y', refit the model and output its summary.**\n",
        "\n",
        "* **5.1) Does the model seems to be a better fit compared to the one with only 'x' and 'y' ?** \n",
        "\n",
        "* **5.2) How do you interpret the coefficients ?**"
      ],
      "metadata": {
        "id": "L3KEoQ0dmJci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f_RuymGVncgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Generate dummy variables out of the variables 'cut', 'color' and 'clarity'. Make sure that for each of those variables, one level was selected as the reference level (and consequently, that this level is not represented by a dummy variable).**\n",
        "\n",
        "**Why do we need to have k-1 dummy variables, when k is the number of levels ?**"
      ],
      "metadata": {
        "id": "Js9HhxqHsCNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bd9A56vMrfo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7) Refit the model using the dummy variables obtained from the variable 'color', and output its summary.**\n",
        "\n",
        "* **7.1) Does the model seem to be a good fit ?**\n",
        "\n",
        "* **7.2) Are all coefficients significant ? if not, what does it mean ?**\n",
        "\n",
        "* **7.3) How do you interpret the coefficients ?**\n"
      ],
      "metadata": {
        "id": "j16LXvghtAPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wC8JCYqMtYgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8) Refit the model using this time all predictor variables (at the exception of price, of course), and output its summary.**\n",
        "\n",
        "**What do you observe ? Does the model seem to be a better fit compared to the previous ones ? Are all coefficients still significant ?**"
      ],
      "metadata": {
        "id": "XjZ2AF9OdOg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fTr9nQ-8r4jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9) We will now select candidate features to fit our model using a forward selection strategy. To this end, we will define different entering criteria for our candidate features :**\n",
        "* Does the introduction of the feature decreases the MSE ? \n",
        "* Does the introduction of the feature decreases the AIC ? \n",
        "* Does the introduction of the feature decreases the BIC ? \n",
        " \n",
        "**To this end, define two new functions : neg_AIC(y_true, y_pred, n, k) and neg_BIC(y_true, y_pred, n, k) that respectively compute the negative AIC and BIC given the ground truth y values (y_true), the predicted y values (y_pred), the number of samples (n) and the number of predictors (k). The AIC and BIC can be computed as such :**\n",
        "\n",
        "* AIC = 2*k + n*log(mse) \n",
        "* BIC = n*log(mse) + k*log(n)"
      ],
      "metadata": {
        "id": "BJBVO1ojhWDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "def forward_selection(df, model, target_column, columns, scoring_rule):\n",
        "  features_to_keep  = []\n",
        "  features_to_try = []  \n",
        "  best_score = -np.inf\n",
        "  cond = True\n",
        "  y = df[target_column].values\n",
        "  while len(columns) != 0 and cond is True:\n",
        "    cond = False\n",
        "    best_feat = None \n",
        "    for col in columns:  \n",
        "      features_to_try = features_to_keep + [col]   \n",
        "      X = get_predictors(df, features_to_try)\n",
        "      n, k = X.shape[0], X.shape[1]\n",
        "      if scoring_rule == 'aic':\n",
        "        scorer = make_scorer(neg_AIC, n=n, k=k, greater_is_better=True)\n",
        "      elif scoring_rule == 'bic':\n",
        "        scorer = make_scorer(neg_BIC, n=n, k=k, greater_is_better=True)\n",
        "      else:\n",
        "        scorer = scoring_rule\n",
        "      cv_results = cross_validate(model, X, y, scoring=scorer, cv=10)\n",
        "      score = cv_results['test_score'].mean()\n",
        "      if score > best_score: \n",
        "        best_feat = col\n",
        "        cond = True\n",
        "        best_score = score\n",
        "    if best_feat != None:\n",
        "      columns.remove(best_feat)\n",
        "      features_to_keep.append(best_feat)\n",
        "  return features_to_keep, best_score \n",
        "\n",
        "def get_predictors(df, cols):\n",
        "  cat_pred = []\n",
        "  cont_pred = []\n",
        "  for col in cols:\n",
        "    if isinstance(df[col].values[0], str):\n",
        "      cat_pred.append(col)\n",
        "    else:\n",
        "      cont_pred.append(col)\n",
        "    if len(cat_pred) != 0:\n",
        "      df_dummies = pd.get_dummies(df[cat_pred], drop_first=True)\n",
        "    else:\n",
        "      df_dummies  = pd.DataFrame() \n",
        "  df_cont = df[cont_pred] \n",
        "  df_cat = pd.concat([df_dummies, df_cont], axis=1)\n",
        "  \n",
        "  return df_cat.values  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EyQkfpnZud5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10) Use the function forward_selection() and the functions neg_AIC() and neg_BIC() to perform a forward selection on the dataframe features (at the exception of carat) to see which subset of features is best to fit the target variable 'price'. Also, do a forward selection with an entering criterion defined as the MSE. When performing selection, do not consider the variable 'carat'.**\n",
        "\n",
        "**For each selection, report the best subset of features obtained, as well as the score obtained. What do you observe ?**  "
      ],
      "metadata": {
        "id": "AS0VH-6mjFXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GNKAsJxVu8jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) The set of predictors obtained when defining the BIC or the AIC as the entering criterion is smaller than the one obtained with the MSE. This is expected, as the AIC and the BIC penalize the inclusion of a new predictor to the model, which is not the case of the MSE. As a general rule, using the BIC might result in a smaller set than when using the AIC, which might in turn results in a smaller set than when using the MSE. "
      ],
      "metadata": {
        "id": "swxJbt0Nj1WK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11) Looking at the scatter plot of the variable 'price' against the variable 'x', a linear model might not be the best fit to explain the relation between the two variables.  Using a transformation of the variable 'x', try to obtain a better fit. Plot the linear regression line and the one obtained using the transformation of 'x'.**"
      ],
      "metadata": {
        "id": "ROq-BPSUkCJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xMrxh-fuBh7Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}